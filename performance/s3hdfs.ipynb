{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe9591a-6563-4a8c-93dc-5abdaaab65b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "from random import randrange\n",
    "from datetime import datetime\n",
    "\n",
    "nr_of_customers = 1000000\n",
    "\n",
    "fake = Faker('de_DE')\n",
    "\n",
    "customers = []\n",
    "\n",
    "for customers_id in range(nr_of_customers):\n",
    "\n",
    "    # Create transaction date \n",
    "    d1 = datetime.strptime(f'1/1/2021', '%m/%d/%Y')\n",
    "    d2 = datetime.strptime(f'8/10/2021', '%m/%d/%Y')\n",
    "    transaction_date = fake.date_between(d1, d2)\n",
    "\n",
    "    #create customer's name\n",
    "    name = fake.name()\n",
    "\n",
    "    # Create gender\n",
    "    gender = random.choice([\"M\", \"F\"])\n",
    "\n",
    "    # Create email \n",
    "    email = fake.ascii_email()\n",
    "\n",
    "    #Create city\n",
    "    city = fake.city()\n",
    "\n",
    "    #create product ID in 8-digit barcode\n",
    "    product_ID = fake.ean(length=8)\n",
    "    \n",
    "    #create amount spent\n",
    "    amount_spent = fake.pyfloat(right_digits=2, positive=True, min_value=1, max_value=100)\n",
    "\n",
    "    customers.append([transaction_date, name, gender, email, city, product_ID, amount_spent])\n",
    "\n",
    "customers_df = pd.DataFrame(customers, columns=['Transaction_date','Name', 'Gender','Email', 'City','Product_id', 'Amount_spent']) \n",
    "                \n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "\n",
    "from hdfs import InsecureClient\n",
    "import os\n",
    "client_hdfs = InsecureClient('http://ec2-13-209-26-180.ap-northeast-2.compute.amazonaws.com:9870/')\n",
    "\n",
    "with client_hdfs.write('/dummy/output.csv', encoding = 'utf-8') as writer:\n",
    "  customers_df.to_csv(writer)\n",
    "#print(customers_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ce306-b762-4ca5-8c26-24a368d243e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "adf = pa.Table.from_pandas(customers_df)  # type: pyarrow.lib.Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef28e73-ba94-4002-a8b4-fe7695019f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.fs.HadoopFileSystem as pq\n",
    "\n",
    "fs  = pa.hdfs.connect()\n",
    "pq.write_parquet(adf, 'dummy.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d8696d-418c-4199-80c0-1c4188f6a493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "response=s3.list_buckets()\n",
    "#print(response)\n",
    "buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "#print(\"Bucket Name: %s\" % buckets)\n",
    "bucket name for upload\n",
    "bucket_name='dummytestdata-octank'\n",
    "file_name='/home/hadoop/dummytestdata.csv'\n",
    "s3.upload_file(file_name,bucket_name,'dummytestdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d8682-f41e-4094-80f7-b333332eaf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "from random import randrange\n",
    "from datetime import datetime\n",
    "import pyarrow as pa\n",
    "import pyarrow.orc as orc\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import boto3\n",
    "\n",
    "nr_of_customers = 20000000\n",
    "\n",
    "fake = Faker('de_DE')\n",
    "\n",
    "customers = []\n",
    "\n",
    "for customers_id in range(nr_of_customers):\n",
    "\n",
    "    # Create transaction date \n",
    "    #d1 = datetime.strptime(f'1/1/2021', '%m/%d/%Y')\n",
    "    #d2 = datetime.strptime(f'8/10/2021', '%m/%d/%Y')\n",
    "    #transaction_date = fake.date_between(d1, d2)\n",
    "    transaction_date = datetime.strptime(f'1/31/2021', '%m/%d/%Y')\n",
    "    \n",
    "    #create product ID in 8-digit barcode\n",
    "    national_ID = fake.ean(length=8)\n",
    "        \n",
    "    #create customer's name\n",
    "    name = fake.name()\n",
    "\n",
    "    # Create gender\n",
    "    gender = random.choice([\"M\", \"F\"])\n",
    "\n",
    "    # Create email \n",
    "    email = fake.ascii_email()\n",
    "\n",
    "    #Create city\n",
    "    city = fake.city()\n",
    "\n",
    "    #create product ID in 8-digit barcode\n",
    "    product_ID = fake.ean(length=8)\n",
    "    \n",
    "    #create amount spent\n",
    "    amount_spent = fake.pyfloat(right_digits=2, positive=True, min_value=1, max_value=100)\n",
    "\n",
    "    customers.append([transaction_date, national_ID, name, gender, email, city, product_ID, amount_spent])\n",
    "\n",
    "customers_df = pd.DataFrame(customers, columns=['Transaction_date','nation_ID','Name', 'Gender','Email', 'City','Product_id', 'Amount_spent']) \n",
    "                \n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "table = pa.Table.from_pandas(customers_df)\n",
    "pq.write_table(table, '/tmp/output.parquet')\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "#response=s3.list_buckets()\n",
    "#print(response)\n",
    "#buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "#print(\"Bucket Name: %s\" % buckets)\n",
    "#bucket name for upload\n",
    "bucket_name='dummytestdata-octank'\n",
    "file_name='/tmp/output.parquet'\n",
    "s3.upload_file(file_name,bucket_name,'output.parquet')\n",
    "\n",
    "\n",
    "\n",
    "#s3 = boto3.client(\"s3\")\n",
    "#    BucketName = bucketName\n",
    "#    with open(fileName) as f:\n",
    "#       object_data = f.read()\n",
    "#       s3.put_object(Body=object_data, Bucket=BucketName, Key=keyName)\n",
    "\n",
    "#fs  = pa.hdfs.connect()\n",
    "\n",
    "#adf = pa.Table.from_pandas(customers_df)\n",
    "\n",
    "\n",
    "#import pyarrow.parquet as pq\n",
    "#fs  = pa.hdfs.connect()\n",
    "#with fs.open('/dummy/output.parquet', \"wb\") as fw\n",
    "#    pq.write_table(adf, fw)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from hdfs import InsecureClient\n",
    "#import os\n",
    "#client_hdfs = InsecureClient('http://ec2-13-125-221-251.ap-northeast-2.compute.amazonaws.com:9870/')\n",
    "\n",
    "#write.format(\"orc\").save(\"people\")\n",
    "#client_hdfs.write.mode(SaveMode.Overwrite).format(\"orc\").save(\"/dummy/output.orc/\")\n",
    "\n",
    "#with client_hdfs.write('/dummy/output.parquet', encoding = 'utf-8') as writer:\n",
    "#      customers_df.to_parquet(writer)\n",
    "#customers_df.to_csv(writer)\n",
    "#print(customers_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ff503e-1a6b-4b9a-ac42-76636198912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install Faker\n",
    "#pip install boto3\n",
    "#pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc678d5-82ee-44bf-8ad6-478ff9ed81c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332af7d1-8962-491e-b842-b8abb8366f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
